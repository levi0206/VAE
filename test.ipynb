{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from models.VAE import VAE, VAE_train\n",
    "from lib.mmd import SignatureKernel,mmd_loss\n",
    "from lib.datasets import get_stock_price,sample_indices,train_test_split\n",
    "from lib.aug import apply_augmentations,parse_augmentations\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List\n",
    "from lib.utils import sample_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "    \"ticker\" : \"^GSPC\",\n",
    "    \"interval\" : \"1d\",\n",
    "    \"column\" : 1,  \n",
    "    \"window_size\" : 20,\n",
    "    \"dir\" : \"datasets\",\n",
    "    \"subdir\" : \"stock\"\n",
    "}\n",
    "sig_config = {\n",
    "    \"augmentations\": [\n",
    "        {\"name\": \"AddTime\"},\n",
    "        {\"name\": \"LeadLag\"},\n",
    "    ],\n",
    "    \"device\" : \"cuda:0\",\n",
    "    \"depth\" : 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolled data for training, shape torch.Size([1232, 20, 1])\n",
      "Before augmentation shape: torch.Size([985, 20, 1])\n",
      "torch.Size([985, 20, 2])\n",
      "torch.Size([985, 39, 4])\n",
      "After augmentation shape: torch.Size([985, 39, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor_data = get_stock_price(data_config)\n",
    "x_real_train, x_real_test = train_test_split(tensor_data, train_test_ratio=0.8, device=sig_config[\"device\"])\n",
    "if sig_config[\"augmentations\"] is not None:\n",
    "    sig_config[\"augmentations\"] = parse_augmentations(sig_config.get('augmentations'))\n",
    "print(\"Before augmentation shape:\",x_real_train.shape)\n",
    "if sig_config[\"augmentations\"] is not None:\n",
    "    # Print the tensor shape after each augmentation\n",
    "    x_aug_sig = apply_augmentations(x_real_train,sig_config[\"augmentations\"])\n",
    "    # Input dimension of encoder\n",
    "    # We'll flat the tensor\n",
    "    input_dim = x_aug_sig.shape[1]*x_aug_sig.shape[2]\n",
    "print(\"After augmentation shape:\",x_aug_sig.shape)\n",
    "x_aug_sig = x_aug_sig.to(sig_config[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function has bug.\n",
    "def compute_mmd(z: torch.Tensor , prior_z: torch.Tensor):\n",
    "    \"\"\" Computes MMD between z and prior_z using RBF kernel. \"\"\"\n",
    "    def rbf_kernel(x, y, sigma=1.0):\n",
    "        x_size = x.size(0)\n",
    "        y_size = y.size(0)\n",
    "        dim = x.size(1)\n",
    "\n",
    "        xx = torch.matmul(x, x.t())  # Shape: (x_size, x_size)\n",
    "        yy = torch.matmul(y, y.t())  # Shape: (y_size, y_size)\n",
    "        xy = torch.matmul(x, y.t())  # Shape: (x_size, y_size)\n",
    "\n",
    "        x_sq = xx.diag().unsqueeze(1).expand_as(xx)\n",
    "        y_sq = yy.diag().unsqueeze(0).expand_as(yy)\n",
    "\n",
    "        dist_xx = x_sq + x_sq.t() - 2 * xx\n",
    "        dist_yy = y_sq + y_sq.t() - 2 * yy\n",
    "        dist_xy = x_sq + y_sq - 2 * xy\n",
    "\n",
    "        sigma_sq = sigma ** 2\n",
    "        k_xx = torch.exp(-dist_xx / (2 * sigma_sq))\n",
    "        k_yy = torch.exp(-dist_yy / (2 * sigma_sq))\n",
    "        k_xy = torch.exp(-dist_xy / (2 * sigma_sq))\n",
    "        print(\"k_xx shape {}\".format(k_xx.shape))\n",
    "        return k_xx, k_yy, k_xy\n",
    "\n",
    "    k_xx, k_yy, k_xy = rbf_kernel(z, z), rbf_kernel(prior_z, prior_z), rbf_kernel(z, prior_z)\n",
    "\n",
    "    mmd = k_xx.mean() + k_yy.mean() - 2 * k_xy.mean()\n",
    "    return mmd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoVAE(nn.Module):\n",
    "    def __init__(self, x_aug_sig, epoch, batch_size, hidden_dims: List, device) -> None:\n",
    "        super(InfoVAE, self).__init__()\n",
    "\n",
    "        self.x_aug_sig = x_aug_sig\n",
    "        print(\"Input tensor shape: {}\".format(x_aug_sig.shape))\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "\n",
    "        # Assume len(hidden_dims)=3.\n",
    "        self.encoder_mu = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[0],hidden_dims[1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dims[1],hidden_dims[2]),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.encoder_sigma = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[0],hidden_dims[1]),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dims[1],hidden_dims[2]),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[2],hidden_dims[1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dims[1],hidden_dims[0]),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        # To device\n",
    "        self.encoder_mu.to(device)\n",
    "        self.encoder_sigma.to(device)\n",
    "        self.decoder.to(device)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x_flatten = x.view(x.shape[0],-1)\n",
    "        mean = self.encoder_mu(x_flatten)\n",
    "        log_var = self.encoder_sigma(x_flatten)\n",
    "        # Clipping\n",
    "        log_var = torch.clamp(log_var, min=-10, max=10)\n",
    "        noise = torch.randn(x.shape[0],mean.shape[1]).to(self.device)\n",
    "        z = mean + torch.exp(0.5*log_var).mul(noise)\n",
    "        return mean, log_var, z\n",
    "        \n",
    "    def decode(self,z):\n",
    "        reconstructed_data = self.decoder(z)\n",
    "        return reconstructed_data\n",
    "\n",
    "    def loss(self,mean, log_var, sample_data, reconstructed_data, lambda_mmd=10):\n",
    "        \"\"\" Compute InfoVAE loss with MMD regularization. \"\"\"\n",
    "        # Reconstruction loss\n",
    "        recon_loss = F.mse_loss(reconstructed_data, sample_data, reduction='sum')\n",
    "\n",
    "        # Sample prior (Standard Normal)\n",
    "        batch_size, z_dim = mean.shape\n",
    "        prior_z = torch.randn(batch_size, z_dim).to(mean.device)\n",
    "\n",
    "        # Compute KL divergence\n",
    "        kl_div = 0.5 * torch.sum(mean.pow(2) + log_var.exp() - 1 - log_var)\n",
    "\n",
    "        # Compute MMD\n",
    "        mmd = compute_mmd(mean, prior_z)\n",
    "\n",
    "        # InfoVAE Loss\n",
    "        loss = recon_loss + lambda_mmd * mmd + (lambda_mmd - 1) * kl_div\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def generate(self,x: torch.Tensor):\n",
    "        _, _, z = self.encode(x)\n",
    "        reconstructed_data = self.decode(z)\n",
    "        return reconstructed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer):\n",
    "    early_stop = 500\n",
    "    cnt = 0\n",
    "    min_loss = float('inf')\n",
    "    for i in range(model.epoch):\n",
    "        # Sample time indices of size equal to the batch size\n",
    "        # From sefl.x_aug_sig\n",
    "        time_indics = sample_indices(model.x_aug_sig.shape[0],model.batch_size,\"cuda\")\n",
    "        sample_data = model.x_aug_sig[time_indics]\n",
    "        # print(\"sample_data shape {}\".format(sample_data.shape))\n",
    "        # Encode \n",
    "        mean, log_var, z = model.encode(sample_data)\n",
    "        # Decode\n",
    "        reconstructed_data = model.decode(z)\n",
    "        # print(\"reconstructed_data shape {},\".format(reconstructed_data.shape))\n",
    "        # Calculate loss\n",
    "        loss = model.loss(mean,log_var,sample_data.view(sample_data.shape[0],-1),reconstructed_data)\n",
    "        # Backpropogation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print loss\n",
    "        if i%500==0:\n",
    "            print(\"Epoch {} loss {}\".format(i,loss.item()))\n",
    "        # Early stop\n",
    "        if loss.item()<min_loss:\n",
    "            min_loss = loss.item()\n",
    "            cnt = 0\n",
    "        else:\n",
    "            cnt += 1\n",
    "            if cnt>early_stop:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([985, 39, 4])\n",
      "InfoVAE(\n",
      "  (encoder_mu): Sequential(\n",
      "    (0): Linear(in_features=156, out_features=12, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=12, out_features=3, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (encoder_sigma): Sequential(\n",
      "    (0): Linear(in_features=156, out_features=12, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=12, out_features=3, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=12, out_features=156, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "batch_size = 200\n",
    "epoch = 20001\n",
    "hidden_dims = [input_dim,12,3]\n",
    "InfoVAE = InfoVAE(x_aug_sig=x_aug_sig,epoch=epoch,batch_size=batch_size,hidden_dims=hidden_dims,device='cuda')\n",
    "print(InfoVAE)\n",
    "optimizer = torch.optim.Adam(InfoVAE.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_xx shape torch.Size([200, 200])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mInfoVAE\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m     14\u001b[0m reconstructed_data \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecode(z)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print(\"reconstructed_data shape {},\".format(reconstructed_data.shape))\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlog_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreconstructed_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Backpropogation\u001b[39;00m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn[5], line 63\u001b[0m, in \u001b[0;36mInfoVAE.loss\u001b[0;34m(self, mean, log_var, sample_data, reconstructed_data, lambda_mmd)\u001b[0m\n\u001b[1;32m     60\u001b[0m kl_div \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(mean\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m log_var\u001b[38;5;241m.\u001b[39mexp() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m log_var)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Compute MMD\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m mmd \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_mmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior_z\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# InfoVAE Loss\u001b[39;00m\n\u001b[1;32m     66\u001b[0m loss \u001b[38;5;241m=\u001b[39m recon_loss \u001b[38;5;241m+\u001b[39m lambda_mmd \u001b[38;5;241m*\u001b[39m mmd \u001b[38;5;241m+\u001b[39m (lambda_mmd \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m kl_div\n",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m, in \u001b[0;36mcompute_mmd\u001b[0;34m(z, prior_z)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk_xx shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k_xx\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m k_xx, k_yy, k_xy\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrbf_kernel(z, z) shape: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mrbf_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m))\n\u001b[1;32m     27\u001b[0m k_xx, k_yy, k_xy \u001b[38;5;241m=\u001b[39m rbf_kernel(z, z), rbf_kernel(prior_z, prior_z), rbf_kernel(z, prior_z)\n\u001b[1;32m     29\u001b[0m mmd \u001b[38;5;241m=\u001b[39m k_xx\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m+\u001b[39m k_yy\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m k_xy\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train(InfoVAE,optimizer=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siggan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
