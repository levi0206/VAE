{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from lib.datasets import get_stock_price,sample_indices,train_test_split\n",
    "from lib.aug import apply_augmentations,parse_augmentations\n",
    "from typing import List\n",
    "from torch import nn\n",
    "from typing import List\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "    \"ticker\" : \"^GSPC\",\n",
    "    \"interval\" : \"1d\",\n",
    "    \"column\" : 1,  \n",
    "    \"window_size\" : 20,\n",
    "    \"dir\" : \"datasets\",\n",
    "    \"subdir\" : \"stock\"\n",
    "}\n",
    "sig_config = {\n",
    "    \"augmentations\": [\n",
    "        {\"name\": \"AddTime\"},\n",
    "        {\"name\": \"LeadLag\"},\n",
    "    ],\n",
    "    \"device\" : \"cuda:0\",\n",
    "    \"depth\" : 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolled data for training, shape torch.Size([1232, 20, 1])\n",
      "Before augmentation shape: torch.Size([985, 20, 1])\n",
      "torch.Size([985, 20, 2])\n",
      "torch.Size([985, 39, 4])\n",
      "After augmentation shape: torch.Size([985, 39, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor_data = get_stock_price(data_config)\n",
    "x_real_train, x_real_test = train_test_split(tensor_data, train_test_ratio=0.8, device=sig_config[\"device\"])\n",
    "if sig_config[\"augmentations\"] is not None:\n",
    "    sig_config[\"augmentations\"] = parse_augmentations(sig_config.get('augmentations'))\n",
    "print(\"Before augmentation shape:\",x_real_train.shape)\n",
    "if sig_config[\"augmentations\"] is not None:\n",
    "    # Print the tensor shape after each augmentation\n",
    "    x_aug_sig = apply_augmentations(x_real_train,sig_config[\"augmentations\"])\n",
    "    input_dim = x_aug_sig.shape[1]*x_aug_sig.shape[2]\n",
    "print(\"After augmentation shape:\",x_aug_sig.shape)\n",
    "x_aug_sig = x_aug_sig.to(sig_config[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_aug_sig, epoch, batch_size, hidden_dims: List, device) -> None:\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.x_aug_sig = x_aug_sig\n",
    "        print(\"Input tensor shape: {}\".format(x_aug_sig.shape))\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "\n",
    "        # Assume len(hidden_dims)=3.\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[0],hidden_dims[1]),\n",
    "            nn.Linear(hidden_dims[1],hidden_dims[2]),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[2],hidden_dims[1]),\n",
    "            nn.Linear(hidden_dims[1],hidden_dims[0]),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        # To device\n",
    "        self.encoder.to(device)\n",
    "        self.decoder.to(device)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x_flatten = x.view(self.batch_size,-1)\n",
    "        mean = self.encoder(x_flatten)\n",
    "        log_var = self.encoder(x_flatten)\n",
    "        noise = torch.randn(self.batch_size,mean.shape[1]).to(self.device)\n",
    "        z = mean + torch.exp(0.5*log_var).mul(noise)\n",
    "        return mean, log_var, z\n",
    "        \n",
    "    def decode(self,z):\n",
    "        reconstructed_data = self.decoder(z)\n",
    "        return reconstructed_data\n",
    "\n",
    "    def loss(self,mean,log_var,sample_data,reconstructed_data):\n",
    "        # Reconstruction loss \n",
    "        recon_loss = F.mse_loss(sample_data, reconstructed_data, reduction='sum')\n",
    "        # print(recon_loss.item())\n",
    "        # KL divergence\n",
    "        kl_loss = 0.5 * torch.sum(mean.pow(2) + log_var.exp() - 1 - log_var)\n",
    "        # Total VAE loss\n",
    "        loss = recon_loss + kl_loss\n",
    "        return loss\n",
    "    \n",
    "def train(model,optimizer):\n",
    "    for i in range(model.epoch):\n",
    "        # Sample time indices of size equal to the batch size.\n",
    "        # From sefl.x_aug_sig\n",
    "        time_indics = sample_indices(model.x_aug_sig.shape[0],model.batch_size,\"cuda\")\n",
    "        sample_data = model.x_aug_sig[time_indics]\n",
    "        # Encode \n",
    "        mean, log_var, z = model.encode(sample_data)\n",
    "        # Decode\n",
    "        reconstructed_data = model.decode(z)\n",
    "        # Calculate loss\n",
    "        loss = model.loss(mean,log_var,sample_data.view(model.batch_size,-1),reconstructed_data)\n",
    "        # Backpropogation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print loss\n",
    "        if i%10==0:\n",
    "            print(\"Epoch {} loss {}\".format(i,loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([985, 39, 4])\n",
      "VAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=156, out_features=60, bias=True)\n",
      "    (1): Linear(in_features=60, out_features=20, bias=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=60, bias=True)\n",
      "    (1): Linear(in_features=60, out_features=156, bias=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-1\n",
    "batch_size = 128\n",
    "epoch = 101\n",
    "hidden_dims = [input_dim,60,20]\n",
    "VAE = VAE(x_aug_sig=x_aug_sig,epoch=epoch,batch_size=batch_size,hidden_dims=hidden_dims,device='cuda')\n",
    "print(VAE)\n",
    "optimizer = torch.optim.Adam(VAE.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss nan\n",
      "Epoch 10 loss nan\n",
      "Epoch 20 loss nan\n",
      "Epoch 30 loss nan\n",
      "Epoch 40 loss nan\n",
      "Epoch 50 loss nan\n",
      "Epoch 60 loss nan\n",
      "Epoch 70 loss nan\n",
      "Epoch 80 loss nan\n",
      "Epoch 90 loss nan\n",
      "Epoch 100 loss nan\n"
     ]
    }
   ],
   "source": [
    "train(VAE,optimizer=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siggan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
