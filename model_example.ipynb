{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from lib.datasets import get_stock_price,sample_indices,train_test_split\n",
    "from lib.aug import apply_augmentations,parse_augmentations\n",
    "from typing import List\n",
    "from torch import nn\n",
    "from typing import List\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "    \"ticker\" : \"^GSPC\",\n",
    "    \"interval\" : \"1d\",\n",
    "    \"column\" : 1,  \n",
    "    \"window_size\" : 20,\n",
    "    \"dir\" : \"datasets\",\n",
    "    \"subdir\" : \"stock\"\n",
    "}\n",
    "sig_config = {\n",
    "    \"augmentations\": [\n",
    "        {\"name\": \"AddTime\"},\n",
    "        {\"name\": \"LeadLag\"},\n",
    "    ],\n",
    "    \"device\" : \"cuda:0\",\n",
    "    \"depth\" : 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolled data for training, shape torch.Size([1232, 20, 1])\n",
      "Before augmentation shape: torch.Size([985, 20, 1])\n",
      "torch.Size([985, 20, 2])\n",
      "torch.Size([985, 39, 4])\n",
      "After augmentation shape: torch.Size([985, 39, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor_data = get_stock_price(data_config)\n",
    "x_real_train, x_real_test = train_test_split(tensor_data, train_test_ratio=0.8, device=sig_config[\"device\"])\n",
    "if sig_config[\"augmentations\"] is not None:\n",
    "    sig_config[\"augmentations\"] = parse_augmentations(sig_config.get('augmentations'))\n",
    "print(\"Before augmentation shape:\",x_real_train.shape)\n",
    "if sig_config[\"augmentations\"] is not None:\n",
    "    # Print the tensor shape after each augmentation\n",
    "    x_aug_sig = apply_augmentations(x_real_train,sig_config[\"augmentations\"])\n",
    "    # Input dimension of encoder\n",
    "    # We'll flat the tensor\n",
    "    input_dim = x_aug_sig.shape[1]*x_aug_sig.shape[2]\n",
    "print(\"After augmentation shape:\",x_aug_sig.shape)\n",
    "x_aug_sig = x_aug_sig.to(sig_config[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_aug_sig, epoch, batch_size, hidden_dims: List, device) -> None:\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.x_aug_sig = x_aug_sig\n",
    "        print(\"Input tensor shape: {}\".format(x_aug_sig.shape))\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "\n",
    "        # Assume len(hidden_dims)=3.\n",
    "        self.encoder_mu = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[0],hidden_dims[1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dims[1],hidden_dims[2]),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.encoder_sigma = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[0],hidden_dims[1]),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dims[1],hidden_dims[2]),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[2],hidden_dims[1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dims[1],hidden_dims[0]),\n",
    "        )\n",
    "\n",
    "        # To device\n",
    "        self.encoder_mu.to(device)\n",
    "        self.encoder_sigma.to(device)\n",
    "        self.decoder.to(device)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x_flatten = x.view(self.batch_size,-1)\n",
    "        mean = self.encoder_mu(x_flatten)\n",
    "        log_var = self.encoder_sigma(x_flatten)\n",
    "        # Clipping\n",
    "        log_var = torch.clamp(log_var, min=-10, max=10)\n",
    "        noise = torch.randn(self.batch_size,mean.shape[1]).to(self.device)\n",
    "        z = mean + torch.exp(0.5*log_var).mul(noise)\n",
    "        return mean, log_var, z\n",
    "        \n",
    "    def decode(self,z):\n",
    "        reconstructed_data = self.decoder(z)\n",
    "        return reconstructed_data\n",
    "\n",
    "    def loss(self,mean,log_var,sample_data,reconstructed_data):\n",
    "        # Reconstruction loss \n",
    "        recon_loss = F.mse_loss(sample_data, reconstructed_data, reduction='mean')\n",
    "        # print(recon_loss.item())\n",
    "        # KL divergence\n",
    "        kl_loss = 0.5 * ((mean.pow(2) + log_var.exp() - 1 - log_var).mean()).sum()\n",
    "        # Total VAE loss\n",
    "        loss = recon_loss + kl_loss\n",
    "        return loss\n",
    "    \n",
    "def train(model,optimizer):\n",
    "    early_stop = 500\n",
    "    cnt = 0\n",
    "    min_loss = float('inf')\n",
    "    for i in range(model.epoch):\n",
    "        # Sample time indices of size equal to the batch size\n",
    "        # From sefl.x_aug_sig\n",
    "        time_indics = sample_indices(model.x_aug_sig.shape[0],model.batch_size,\"cuda\")\n",
    "        sample_data = model.x_aug_sig[time_indics]\n",
    "        # Encode \n",
    "        mean, log_var, z = model.encode(sample_data)\n",
    "        # Decode\n",
    "        reconstructed_data = model.decode(z)\n",
    "        # Calculate loss\n",
    "        loss = model.loss(mean,log_var,sample_data.view(model.batch_size,-1),reconstructed_data)\n",
    "        # Backpropogation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print loss\n",
    "        if i%500==0:\n",
    "            print(\"Epoch {} loss {}\".format(i,loss.item()))\n",
    "        # Early stop\n",
    "        if loss.item()<min_loss:\n",
    "            min_loss = loss.item()\n",
    "            cnt = 0\n",
    "        else:\n",
    "            cnt += 1\n",
    "            if cnt>early_stop:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([985, 39, 4])\n",
      "VAE(\n",
      "  (encoder_mu): Sequential(\n",
      "    (0): Linear(in_features=156, out_features=12, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=12, out_features=3, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (encoder_sigma): Sequential(\n",
      "    (0): Linear(in_features=156, out_features=12, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=12, out_features=3, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=12, out_features=156, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "batch_size = 200\n",
    "epoch = 20001\n",
    "hidden_dims = [input_dim,12,3]\n",
    "VAE = VAE(x_aug_sig=x_aug_sig,epoch=epoch,batch_size=batch_size,hidden_dims=hidden_dims,device='cuda')\n",
    "print(VAE)\n",
    "optimizer = torch.optim.Adam(VAE.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After add a line ``log_var = torch.clamp(log_var, min=-10, max=10)``, the loss is no longer ``nan``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 9686226.0\n",
      "Epoch 500 loss 9070517.0\n",
      "Epoch 1000 loss 6220897.0\n",
      "Epoch 1500 loss 1736919.5\n",
      "Epoch 2000 loss 1202789.875\n",
      "Epoch 2500 loss 930679.0625\n",
      "Epoch 3000 loss 741196.25\n",
      "Epoch 3500 loss 614923.6875\n",
      "Epoch 4000 loss 490475.0625\n",
      "Epoch 4500 loss 430703.84375\n",
      "Epoch 5000 loss 359672.21875\n",
      "Epoch 5500 loss 289123.28125\n",
      "Epoch 6000 loss 264180.875\n",
      "Epoch 6500 loss 215572.90625\n",
      "Epoch 7000 loss 190932.40625\n",
      "Epoch 7500 loss 163359.484375\n",
      "Epoch 8000 loss 138938.828125\n",
      "Epoch 8500 loss 120657.2578125\n",
      "Epoch 9000 loss 106078.2421875\n",
      "Epoch 9500 loss 94310.390625\n",
      "Epoch 10000 loss 80251.2265625\n",
      "Epoch 10500 loss 73686.34375\n",
      "Epoch 11000 loss 64317.55078125\n",
      "Epoch 11500 loss 54875.4921875\n",
      "Epoch 12000 loss 48903.71875\n",
      "Epoch 12500 loss 45501.37109375\n",
      "Epoch 13000 loss 39819.52734375\n",
      "Epoch 13500 loss 36470.34765625\n",
      "Epoch 14000 loss 31373.701171875\n",
      "Epoch 14500 loss 29083.810546875\n",
      "Epoch 15000 loss 25622.19921875\n",
      "Epoch 15500 loss 23948.1796875\n",
      "Epoch 16000 loss 21517.134765625\n",
      "Epoch 16500 loss 19108.3671875\n",
      "Epoch 17000 loss 18994.958984375\n",
      "Epoch 17500 loss 16343.6787109375\n",
      "Epoch 18000 loss 15438.0556640625\n",
      "Epoch 18500 loss 14405.46875\n",
      "Epoch 19000 loss 13313.5087890625\n",
      "Epoch 19500 loss 13067.859375\n",
      "Epoch 20000 loss 12200.068359375\n"
     ]
    }
   ],
   "source": [
    "train(VAE,optimizer=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siggan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
