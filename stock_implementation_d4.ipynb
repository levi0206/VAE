{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.datasets import get_stock_price,train_test_split\n",
    "from lib.aug import apply_augmentations,parse_augmentations,sig_normal\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from lib.utils import set_seed\n",
    "import signatory\n",
    "from models.vae import VAE, VAE_train\n",
    "from models.betavae import BetaVAE, BetaVAE_train\n",
    "from models.infovae import InfoVAE, InfoVAE_train\n",
    "from models.wae import WAE,WAE_train\n",
    "from lib.metrics import mmd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The considered truncated signature degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_degree = [3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "    \"ticker\" : \"^GSPC\",\n",
    "    \"interval\" : \"1d\",\n",
    "    \"column\" : 1,  \n",
    "    \"window_size\" : 20,\n",
    "    \"dir\" : \"datasets\",\n",
    "    \"subdir\" : \"stock\"\n",
    "}\n",
    "sig_config = {\n",
    "    \"augmentations\": [{\"name\": \"LeadLag\"}],\n",
    "    \"device\" : \"cuda\",\n",
    "    \"depth\" : sig_degree[1], # degree = 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get path augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sig_config[\"augmentations\"] is not None:\n",
    "    sig_config[\"augmentations\"] = parse_augmentations(sig_config.get('augmentations'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing.\n",
    "- Split training data and testing data.\n",
    "- Apply path augmentations to original path.\n",
    "- Calculate signature.\n",
    "- Normalize signatures.\n",
    "- Pass to CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolled data for training, shape torch.Size([1232, 20, 1])\n",
      "x_real_train shape torch.Size([985, 20, 1]), x_real_test shape torch.Size([247, 20, 1])\n",
      "torch.Size([985, 39, 2])\n",
      "torch.Size([247, 39, 2])\n",
      "After augmentation shape: torch.Size([985, 39, 2])\n",
      "x_sig_train shape torch.Size([985, 30]), x_sig_test shape torch.Size([247, 30])\n",
      "input_dim: 30\n"
     ]
    }
   ],
   "source": [
    "tensor_data = get_stock_price(data_config)\n",
    "x_real_train, x_real_test = train_test_split(tensor_data, train_test_ratio=0.8, device=sig_config[\"device\"])\n",
    "print(\"x_real_train shape {}, x_real_test shape {}\".format(x_real_train.shape,x_real_test.shape))\n",
    "\n",
    "if sig_config[\"augmentations\"] is not None:\n",
    "    # Print the tensor shape after each augmentation\n",
    "    x_aug_train, x_aug_test = apply_augmentations(x_real_train,sig_config[\"augmentations\"]), apply_augmentations(x_real_test,sig_config[\"augmentations\"])\n",
    "print(\"After augmentation shape:\",x_aug_train.shape)\n",
    "\n",
    "# To signature\n",
    "x_sig_train, x_sig_test = signatory.signature(x_aug_train,sig_config[\"depth\"]),signatory.signature(x_aug_test,sig_config[\"depth\"])\n",
    "print(\"x_sig_train shape {}, x_sig_test shape {}\".format(x_sig_train.shape,x_sig_test.shape))\n",
    "input_dim = x_sig_train.shape[1]\n",
    "print(\"input_dim: {}\".format(input_dim))\n",
    "\n",
    "# Normalize\n",
    "x_sig_train, x_sig_test = sig_normal(x_sig_train,True), sig_normal(x_sig_test,True)\n",
    "\n",
    "# To device\n",
    "x_sig_train, x_sig_test = x_sig_train.to(sig_config[\"device\"]), x_sig_test.to(sig_config[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For degree = 3\n",
    "hidden_dim_degree3 = [input_dim,7,3] # input_dim = 14\n",
    "\n",
    "# For degree = 4\n",
    "hidden_dim_degree4 = [input_dim,15,7] # input_dim = 30\n",
    "\n",
    "# For degree = 5\n",
    "hidden_dim_degree5 = [input_dim,32,16] # input_dim = 62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set degree = 4. Initialize models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([985, 30])\n",
      "Hidden dims: [30, 15, 7]\n",
      "Epoch 0 loss 1.09\n",
      "Epoch 100 loss 0.40\n",
      "Epoch 200 loss 0.41\n",
      "Epoch 300 loss 1.36\n",
      "Epoch 400 loss 0.34\n",
      "Epoch 500 loss 0.50\n",
      "min_loss: 0.23\n"
     ]
    }
   ],
   "source": [
    "# VAE\n",
    "model_vae = VAE(x_aug_sig=x_sig_train,epoch=6000,batch_size=128,device=\"cuda\",hidden_dims=hidden_dim_degree4)\n",
    "vae_optimizer = torch.optim.Adam(model_vae.parameters(), lr=1e-4)\n",
    "VAE_train(model_vae,optimizer=vae_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([985, 30])\n",
      "Hidden dims: [30, 15, 7]\n",
      "Beta: 3.5\n",
      "Epoch 0 loss 42.91\n",
      "Epoch 100 loss 29.02\n",
      "Epoch 200 loss 44.71\n",
      "Epoch 300 loss 9.05\n",
      "Epoch 400 loss 32.44\n",
      "min_loss: 6.39\n"
     ]
    }
   ],
   "source": [
    "# Beta-VAE\n",
    "model_betavae = BetaVAE(x_sig_train,6000,128,beta=3.5,device='cuda',hidden_dims=hidden_dim_degree4)\n",
    "beta_optimizer = torch.optim.Adam(model_betavae.parameters(), lr=1e-4)\n",
    "BetaVAE_train(model=model_betavae,optimizer=beta_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([985, 30])\n",
      "Hidden dims: [30, 15, 7]\n",
      "Epoch 0 loss 0.55\n",
      "Epoch 100 loss 1.91\n",
      "Epoch 200 loss 1.74\n",
      "Epoch 300 loss 0.49\n",
      "Epoch 400 loss 0.53\n",
      "min_loss: 0.39\n"
     ]
    }
   ],
   "source": [
    "# Info-VAE\n",
    "model_infovae = InfoVAE(x_aug_sig=x_sig_train,epoch=6000,batch_size=128,hidden_dims=hidden_dim_degree4,device='cuda')\n",
    "info_optimizer = torch.optim.Adam(model_infovae.parameters(), lr=1e-4) \n",
    "InfoVAE_train(model_infovae,info_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 1.66\n",
      "Epoch 100 loss 0.32\n",
      "Epoch 200 loss 1.28\n",
      "Epoch 300 loss 0.36\n",
      "Epoch 400 loss 1.26\n",
      "Epoch 500 loss 1.27\n",
      "Epoch 600 loss 2.96\n",
      "min_loss: 0.25\n"
     ]
    }
   ],
   "source": [
    "# WAE-MMD\n",
    "model_waemmd = WAE(x_aug_sig=x_sig_train,epoch=6000,batch_size=128,hidden_dims=hidden_dim_degree4,device='cuda')\n",
    "cvae_optimizer = torch.optim.Adam(model_waemmd.parameters(), lr=1e-4) \n",
    "WAE_train(model_waemmd,cvae_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "KLD = nn.KLDivLoss(reduction=\"batchmean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 (VAE): 1.869\n",
      "JS (VAE): 1.846\n",
      "mmd (VAE): -0.243\n",
      "L2 (Beta-VAE): 1.895\n",
      "JS (Beta-VAE): 2.188\n",
      "mmd (Beta-VAE): -0.243\n",
      "L2 (Info-VAE): 1.816\n",
      "JS (Info-VAE): 0.830\n",
      "mmd (Info-VAE): -0.243\n",
      "L2 (WAE): 1.890\n",
      "JS (WAE): 2.195\n",
      "mmd (WAE): -0.243\n"
     ]
    }
   ],
   "source": [
    "models = [model_vae,model_betavae,model_infovae,model_waemmd]\n",
    "for model in models:\n",
    "    _, _, z = model_vae.encode(x_sig_test)\n",
    "    reconstructed_sig = model_vae.decode(z)\n",
    "    reconstructed_sig = sig_normal(reconstructed_sig,True)\n",
    "\n",
    "    # Mean of L2 norm over the batch dimension\n",
    "    L2 = F.mse_loss(x_sig_test,reconstructed_sig)\n",
    "    # Mean of JS divergence over the batch dimension\n",
    "    js = (KLD(x_sig_test,reconstructed_sig)+KLD(reconstructed_sig,x_sig_test))/2\n",
    "    # signature MMD\n",
    "    mmd = mmd_loss(x_sig_test,reconstructed_sig)\n",
    "\n",
    "    print(\"L2 ({}): {:.3f}\".format(model.type,L2.item()))\n",
    "    print(\"JS ({}): {:.3f}\".format(model.type,js.item()))\n",
    "    print(\"mmd ({}): {:.3f}\".format(model.type,mmd.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siggan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
